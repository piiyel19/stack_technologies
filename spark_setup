1) Ssh Terminal & Install Docker 

2) create folder myspark 

3) Create folder data

4) nano docker-compose.yml

version: "2"

services:
  master:
    image: singularities/spark
    command: start-spark master
    hostname: master
    ports:
      - "6066:6066"
      - "7070:7070"
      - "8080:8080"
      - "8021:8020"
      - "50070:50070"
    volumes:
      - ./data:/tmp/data/
  worker:
    image: singularities/spark
    command: start-spark worker master
    environment:
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 2g
    links:
      - master
networks:
  default:
    internal: false
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: ds-net
      
      
      
5) docker-compose up


___________________________________________________________________________________


Cara Guna Spark : 

1) masuk ke container 

docker exec -it myspark_master_1 sh

2) taip command : 

su spark 

3) run 

pyspark

